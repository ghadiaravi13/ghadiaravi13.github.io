---
layout: page
title: Hi, I'm Ravi
subtitle: MS Student in ECE, UT Austin
use-site-title: true
---

<img src="IMG-0081.jpg" alt="Alt Text", style="width: 210px; height: auto; display: block; margin-left: auto; margin-right: auto;">

<br><br>I am a second-year Master's student in Electrical and Computer Engineering at the University of Texas at Austin, focusing on Computing Systems for
Large Scale AI. I am currently working as a research assistant with <a href="https://www.poulamidas.com/">Dr. Poulami Das</a>, where I am working on 
improving the LLM inference efficiency driven by fundamental Computer Architecture principles.<br>

I recently completed an internship at Together.ai, working as a researcher on the training team. My work focused on improving LLM training efficiency for long-context scenarios.
My proposed method of splitting attention head-wise and pipelining them enabled better memory efficiency for long-context training, allowing to train a Llama-8B model on a single 8xH100
node with upto 5M tokens in context (beating the prior SOTA of 4M tokens).

<br>Prior to this, I worked as a GPU Architect at <a href="https://www.nvidia.com/en-in/">NVIDIA, Bengaluru</a>, working on GPU Architecture optimization, 
where I built ML-powered predictive models to project performance for NVIDIA's future products. I also helped build analytical models to debug inefficiencies
in the current products, particularly for the gaming market (e.g <a href="https://www.nvidia.com/en-us/geforce/technologies/dlss/"> NVIDIA DLSS</a>).
Additionally, I have worked as a part-time researcher at <a href="https://h2lab.cs.washington.edu/">H2Lab, University of Washington</a> with <a href="http://prithvirajva.com/">
Prof. Prithviraj Ammanabrolu</a>, where I worked on deriving rewards from freeform linguistic feedback to train Large Language Models using RL.<br>

<br>My research interests lie in designing efficient systems for running massive AI models. To this end, I am interested to explore different layers of the system: hardware architecture,
compilation techniques, kernel-level software optimizations and library-level (e.g PyTorch) optimizations. I have been fortunate to have an exposure to each of these aspects across different
projects during internships as well as coursework. On a tangential note, I am also interested to pursue Reinforcement Learning based finetuning, and interpretability research.<br>

<br>I graduated from IIT Kharagpur in 2021 with a major in Electronics and Elec. Comm. and a minor in Computer Science. My bachelor thesis was on <a href="https://arxiv.org/abs/2205.10558"> <i>Training Generative Dialog Models using Reinforcement Learning with Learned Reward Systems</i></a>, supervised by <a href="https://cse.iitkgp.ac.in/~pawang/">Dr. Pawan Goyal</a>.<br>

<br>My hobbies include trekking, music, cooking (traditional Indian cuisines). I also love reading blogs on abstract ideas, particularly related to tech-stuff and human evolution.<br>

<hr style="height:2px;border-width:0;color:gray;background-color:gray">
